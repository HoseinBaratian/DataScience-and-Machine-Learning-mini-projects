{"cells":[{"source":"# Practical Exam: Customer Purchase Prediction\n\nRetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n\nThe company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n\nTheir marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n\nAs an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n\n\n## Data Description\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"8d0bcede-0826-475c-8678-72835c042b37","cell_type":"markdown"},{"source":"# Task 1\n\nThe marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\nCreate a cleaned version of the dataframe:\n\n- Start with the data in the file `raw_customer_data.csv`\n- Your output should be a DataFrame named `clean_data`\n- All column names and values should match the table below.\n</br>\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"c0d5a3bb-bbae-4d39-a6c6-daa46c470347","cell_type":"markdown"},{"source":"import pandas as pd\n\n# خواندن داده‌های خام\nraw_data = pd.read_csv(\"raw_customer_data.csv\")\n\n# جایگزینی مقادیر گم‌شده\nraw_data[\"time_spent\"].fillna(raw_data[\"time_spent\"].median(), inplace=True)\nraw_data[\"pages_viewed\"].fillna(round(raw_data[\"pages_viewed\"].mean()), inplace=True)\nraw_data[\"basket_value\"].fillna(0, inplace=True)\nraw_data[\"device_type\"].fillna(\"Unknown\", inplace=True)\nraw_data[\"customer_type\"].fillna(\"New\", inplace=True)\n\n# اطمینان از نوع داده‌های صحیح\nraw_data[\"customer_id\"] = raw_data[\"customer_id\"].astype(int)\nraw_data[\"time_spent\"] = raw_data[\"time_spent\"].astype(float)\nraw_data[\"pages_viewed\"] = raw_data[\"pages_viewed\"].astype(int)\nraw_data[\"basket_value\"] = raw_data[\"basket_value\"].astype(float)\nraw_data[\"purchase\"] = raw_data[\"purchase\"].astype(int)\n\n# ذخیره دیتاست پاک‌شده\nclean_data = raw_data\nprint(clean_data.head())\n","metadata":{"executionCancelledAt":null,"executionTime":28,"lastExecutedAt":1740318816444,"lastExecutedByKernel":"2b2b05eb-8a38-4243-825b-6769eac50494","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# خواندن داده‌های خام\nraw_data = pd.read_csv(\"raw_customer_data.csv\")\n\n# جایگزینی مقادیر گم‌شده\nraw_data[\"time_spent\"].fillna(raw_data[\"time_spent\"].median(), inplace=True)\nraw_data[\"pages_viewed\"].fillna(round(raw_data[\"pages_viewed\"].mean()), inplace=True)\nraw_data[\"basket_value\"].fillna(0, inplace=True)\nraw_data[\"device_type\"].fillna(\"Unknown\", inplace=True)\nraw_data[\"customer_type\"].fillna(\"New\", inplace=True)\n\n# اطمینان از نوع داده‌های صحیح\nraw_data[\"customer_id\"] = raw_data[\"customer_id\"].astype(int)\nraw_data[\"time_spent\"] = raw_data[\"time_spent\"].astype(float)\nraw_data[\"pages_viewed\"] = raw_data[\"pages_viewed\"].astype(int)\nraw_data[\"basket_value\"] = raw_data[\"basket_value\"].astype(float)\nraw_data[\"purchase\"] = raw_data[\"purchase\"].astype(int)\n\n# ذخیره دیتاست پاک‌شده\nclean_data = raw_data\nprint(clean_data.head())\n","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","cell_type":"code","execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":"   customer_id  time_spent  pages_viewed  ...  device_type customer_type purchase\n0            1   23.097867             7  ...       Mobile     Returning        0\n1            2   57.092144             3  ...       Mobile     Returning        1\n2            3   44.187643            14  ...       Mobile     Returning        0\n3            4   36.320851            10  ...       Mobile           New        1\n4            5   10.205100            16  ...       Mobile     Returning        1\n\n[5 rows x 7 columns]\n"}]},{"source":"# Task 2\nThe pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\nCreate the model features:\n\n- Start with the data in the file `model_data.csv`\n- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n","metadata":{},"id":"026b3c30-d3b0-4762-ae10-0f2880873bdc","cell_type":"markdown"},{"source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# خواندن داده‌ها از فایل\nraw_data = pd.read_csv(\"model_data.csv\")\n\n# مقیاس‌گذاری ویژگی‌های عددی\nscaler = MinMaxScaler()\nraw_data[[\"time_spent\", \"pages_viewed\", \"basket_value\"]] = scaler.fit_transform(raw_data[[\"time_spent\", \"pages_viewed\", \"basket_value\"]])\n\n# اعمال One-Hot Encoding بر روی ویژگی‌های دسته‌ای\ndummy_variables = pd.get_dummies(raw_data[[\"device_type\", \"customer_type\"]], prefix=[\"device_type\", \"customer_type\"])\n\n# ترکیب داده‌های اصلی با داده‌های وان-هات اینکود شده\nmodel_feature_set = pd.concat([raw_data.drop(columns=[\"device_type\", \"customer_type\"]), dummy_variables], axis=1)\n\n# نمایش خلاصه‌ای از داده‌های پردازش‌شده\nprint(model_feature_set.info())\nprint(model_feature_set.head())","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1740318816494,"lastExecutedByKernel":"2b2b05eb-8a38-4243-825b-6769eac50494","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# خواندن داده‌ها از فایل\nraw_data = pd.read_csv(\"model_data.csv\")\n\n# مقیاس‌گذاری ویژگی‌های عددی\nscaler = MinMaxScaler()\nraw_data[[\"time_spent\", \"pages_viewed\", \"basket_value\"]] = scaler.fit_transform(raw_data[[\"time_spent\", \"pages_viewed\", \"basket_value\"]])\n\n# اعمال One-Hot Encoding بر روی ویژگی‌های دسته‌ای\ndummy_variables = pd.get_dummies(raw_data[[\"device_type\", \"customer_type\"]], prefix=[\"device_type\", \"customer_type\"])\n\n# ترکیب داده‌های اصلی با داده‌های وان-هات اینکود شده\nmodel_feature_set = pd.concat([raw_data.drop(columns=[\"device_type\", \"customer_type\"]), dummy_variables], axis=1)\n\n# نمایش خلاصه‌ای از داده‌های پردازش‌شده\nprint(model_feature_set.info())\nprint(model_feature_set.head())","outputsMetadata":{"0":{"height":584,"type":"stream"}}},"id":"6d47e440-c4ab-45cf-af40-53181764bac4","cell_type":"code","execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 11 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   customer_id              500 non-null    int64  \n 1   time_spent               500 non-null    float64\n 2   pages_viewed             500 non-null    float64\n 3   basket_value             500 non-null    float64\n 4   purchase                 500 non-null    int64  \n 5   device_type_Desktop      500 non-null    uint8  \n 6   device_type_Mobile       500 non-null    uint8  \n 7   device_type_Tablet       500 non-null    uint8  \n 8   device_type_Unknown      500 non-null    uint8  \n 9   customer_type_New        500 non-null    uint8  \n 10  customer_type_Returning  500 non-null    uint8  \ndtypes: float64(3), int64(2), uint8(6)\nmemory usage: 22.6 KB\nNone\n   customer_id  time_spent  ...  customer_type_New  customer_type_Returning\n0          501    0.664167  ...                  1                        0\n1          502    0.483681  ...                  0                        1\n2          503    0.231359  ...                  0                        1\n3          504    0.792944  ...                  1                        0\n4          505    0.649210  ...                  1                        0\n\n[5 rows x 11 columns]\n"}]},{"source":"# Task 3\n\nNow that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n\n- Using PyTorch, create a network with:\n   - At least one hidden layer with 8 units\n   - ReLU activation for hidden layer\n   - Sigmoid activation for the output layer\n- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n","metadata":{},"id":"10a02327-d528-441c-87bf-098f9d6415e1","cell_type":"markdown"},{"source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\n# خواندن داده‌ها\ntrain_data = pd.read_csv(\"input_model_features.csv\")\nvalidation_data = pd.read_csv(\"validation_features.csv\")\n\n# مقیاس‌گذاری ویژگی‌های عددی\nscaler = MinMaxScaler()\nnumeric_features = [\"time_spent\", \"pages_viewed\", \"basket_value\"]\ntrain_data[numeric_features] = scaler.fit_transform(train_data[numeric_features])\nvalidation_data[numeric_features] = scaler.transform(validation_data[numeric_features])\n\n# آماده‌سازی داده‌ها برای مدل\nX_train = torch.tensor(train_data.drop(columns=[\"customer_id\", \"purchase\"]).values, dtype=torch.float32)\ny_train = torch.tensor(train_data[\"purchase\"].values, dtype=torch.float32).view(-1, 1)\nX_val = torch.tensor(validation_data.drop(columns=[\"customer_id\"]).values, dtype=torch.float32)\n\n# تعریف مدل شبکه عصبی\nclass PurchasePredictionModel(nn.Module):\n    def __init__(self, input_dim):\n        super(PurchasePredictionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 8)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(8, 1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return x\n\n# مقداردهی مدل\ninput_dim = X_train.shape[1]\npurchase_model = PurchasePredictionModel(input_dim)\n\n# تنظیم تابع هزینه و بهینه‌ساز\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(purchase_model.parameters(), lr=0.001)\n\n# آموزش مدل\nepochs = 50\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    outputs = purchase_model(X_train)\n    loss = criterion(outputs, y_train)\n    loss.backward()\n    optimizer.step()\n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n\n# پیش‌بینی روی داده‌های آموزش و اعتبارسنجی\nwith torch.no_grad():\n    train_predictions = purchase_model(X_train).numpy()\n    val_predictions = purchase_model(X_val).numpy()\n\n# تبدیل خروجی به ۰ و ۱\ntrain_pred_labels = (train_predictions > 0.5).astype(int)\n\n# محاسبه دقت مدل\ntrain_accuracy = accuracy_score(y_train.numpy(), train_pred_labels)\nprint(f'Training Accuracy: {train_accuracy:.4f}')\n\n# ذخیره پیش‌بینی‌ها\nvalidation_data[\"purchase\"] = (val_predictions > 0.5).astype(int)\nvalidation_predictions = validation_data[[\"customer_id\", \"purchase\"]]\nprint(validation_predictions.head())\n","metadata":{"executionCancelledAt":null,"executionTime":108,"lastExecutedAt":1740318816602,"lastExecutedByKernel":"2b2b05eb-8a38-4243-825b-6769eac50494","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\n# خواندن داده‌ها\ntrain_data = pd.read_csv(\"input_model_features.csv\")\nvalidation_data = pd.read_csv(\"validation_features.csv\")\n\n# مقیاس‌گذاری ویژگی‌های عددی\nscaler = MinMaxScaler()\nnumeric_features = [\"time_spent\", \"pages_viewed\", \"basket_value\"]\ntrain_data[numeric_features] = scaler.fit_transform(train_data[numeric_features])\nvalidation_data[numeric_features] = scaler.transform(validation_data[numeric_features])\n\n# آماده‌سازی داده‌ها برای مدل\nX_train = torch.tensor(train_data.drop(columns=[\"customer_id\", \"purchase\"]).values, dtype=torch.float32)\ny_train = torch.tensor(train_data[\"purchase\"].values, dtype=torch.float32).view(-1, 1)\nX_val = torch.tensor(validation_data.drop(columns=[\"customer_id\"]).values, dtype=torch.float32)\n\n# تعریف مدل شبکه عصبی\nclass PurchasePredictionModel(nn.Module):\n    def __init__(self, input_dim):\n        super(PurchasePredictionModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 8)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(8, 1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return x\n\n# مقداردهی مدل\ninput_dim = X_train.shape[1]\npurchase_model = PurchasePredictionModel(input_dim)\n\n# تنظیم تابع هزینه و بهینه‌ساز\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(purchase_model.parameters(), lr=0.001)\n\n# آموزش مدل\nepochs = 50\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    outputs = purchase_model(X_train)\n    loss = criterion(outputs, y_train)\n    loss.backward()\n    optimizer.step()\n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n\n# پیش‌بینی روی داده‌های آموزش و اعتبارسنجی\nwith torch.no_grad():\n    train_predictions = purchase_model(X_train).numpy()\n    val_predictions = purchase_model(X_val).numpy()\n\n# تبدیل خروجی به ۰ و ۱\ntrain_pred_labels = (train_predictions > 0.5).astype(int)\n\n# محاسبه دقت مدل\ntrain_accuracy = accuracy_score(y_train.numpy(), train_pred_labels)\nprint(f'Training Accuracy: {train_accuracy:.4f}')\n\n# ذخیره پیش‌بینی‌ها\nvalidation_data[\"purchase\"] = (val_predictions > 0.5).astype(int)\nvalidation_predictions = validation_data[[\"customer_id\", \"purchase\"]]\nprint(validation_predictions.head())\n","outputsMetadata":{"0":{"height":269,"type":"stream"}}},"id":"efcbda28-3c89-480d-b77a-c7f27ac759d5","cell_type":"code","execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [10/50], Loss: 0.7031\nEpoch [20/50], Loss: 0.6895\nEpoch [30/50], Loss: 0.6754\nEpoch [40/50], Loss: 0.6605\nEpoch [50/50], Loss: 0.6448\nTraining Accuracy: 0.7762\n   customer_id  purchase\n0         1801         1\n1         1802         1\n2         1803         1\n3         1804         1\n4         1805         1\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}